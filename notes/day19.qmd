---
title: Diagonalization of Symmetric Matrices
author: Jeremy Teitelbaum
format: beamer
---

## Symmetric Matrices

A matrix $A$ is *symmetric* if $A^{T}=A$.  For example
$$
A =\left[\begin{matrix}1 & 3 & 1 \\ 3 & -5 & 7 \\ 1 & 7 & 2 \end{matrix}\right]
$$
is symmetric.

In our discussion of least squares fitting, we ended up with  the matrix $X^{T}X$ 
where $X$ was our data matrix.  This matrix is symmetric because $(X^{T}X)^{T}=X^{T}X$.

If $U$ is a matrix is an $n\times m$ matrix with columns $u_{i}$ for $i=1,\ldots,m$, then $U^{T}U$ is an $m\times m$ matrix whose $i,j$ entry is the dot product of $u_i$ and $u_j$.  It is symmetric because the dot product is commutative.

## Eigenvalues/vectors of symmetric matrices

Eigenvalues and vectors of symmetric matrices have special properties.
Suppose $A$ is an $n\times n$ symmetric matrix.

Theorem: If $v$ and $w$ are eigenvectors of $A$ with eigenvalues $\lambda$ and $\mu$ where $\lambda\not=\mu$ then $v\cdot w=0$. 

To see this, consider $Av=\lambda v$ and $Aw=\mu w$.  Then $w^{T}A^{T}=\mu w^{T}$.
But $A^{T}=A$ wo $w^{T}A=\mu w^{T}$.  

Remember that $w^{T}v=w\cdot v$. 

This gives us
$$
w^{T}Av=\mu(w^{T}v) = \mu(w\cdot v) = \lambda(w^{T}v)=\lambda(w\cdot v)
$$

Since $\lambda\not=\mu$ this means $w\cdot v=0$. 

## Every matrix has at least one complex eigenvalue.

This follows from the fact that the characteristic equation of $A$ must have a root in $\mathbf{C}$. 

## Eigenvalues of symmetric matrices are real numbers (digression)

Suppose that $Av=\lambda v$ is an eigenvector for $A$ corresponding to the eigenvalue $\lambda$.  

Then $A\overline{v}=\overline{\lambda}\overline{v}$ so $\overline{v}$ is an eigenvector with eigenvalue $\overline{\lambda}$.  Then
$$
\overline{v}^{T}A^{T}=\overline{v}^{T}A=\overline{\lambda}\overline{v}^{T}.
$$

Therefore $\overline{v}^{T}Av =\overline{\lambda}(\overline{v}\cdot v)$
and also $\overline{v}^{T}Av=\lambda(\overline{v}\cdot v)$.

Now $\overline{v}\cdot v$ is a positive real number. Therefore $\overline{\lambda}=\lambda$, so $\lambda$ is a real number.

## Inductive step

Suppose $v$ is an eigenvector of $A$ with eigenvalue $\lambda$.  Let $W$ be the 
orthogonal complement of $v$.  If $w\in W$ then $Aw\in W$ because
$$
v^{T}Aw = w^{T}Av=\lambda(w^{T}v) = \lambda(w\cdot v)=0
$$

