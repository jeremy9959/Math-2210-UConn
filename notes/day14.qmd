---
title: Eigenvectors and Linear Transformations
author: Jeremy Teitelbaum
format: beamer
---

## Linear Transformations and Matrices

Remember that a linear transformation $T:\mathbf{R}^{m}\to\mathbf{R}^{n}$ is a function
that satisfies the two conditions:

- $T(ax)=aT(x)$ for all $x\in\mathbf{R}^{m}$ and $a\in\mathbf{R}$.
- $T(x+y)=T(x)+T(y)$ for all $x,y\in\mathbf{R}^{m}$. 

We saw earlier that a linear transformation can be represented by an $n\times m$ matrix $A$
where

$$
T(x_1,\ldots, x_m) = A\left[\begin{matrix} x_1 \\ \vdots \\ x_n\end{matrix}\right]
$$

## Linear transformations and bases

We can take a slightly more general point of view on matrices and linear transformations. 

In the earlier version we used "standard coordinates" where $x_1,\ldots, x_n$ are relative to the "standard basis."

Now suppose $B=\{b_1,\ldots, b_n\}$ are a basis for $\mathbf{R}^{n}$.
Then if
$$
x=r_1 b_1 + \cdots + r_n b_n
$$
we have the coordinate vector
$$
[x]_B=\left[\begin{matrix} r_1 \\ r_2 \\ \vdots \\ r_n\end{matrix}\right].
$$

## Linear transformations in other bases

By linearity 

$$
T(x) = T(r_1 b_1 + \cdots + r_n b_n)= r_1 T(b_1)+\cdots+ r_{n}T(b_n)
$$

Furthermore, each $T(b_{i})$ has coordinates $[T(b_i)]_{B}$ so that
$$
T(b_i) = t_{i1}b_{1} + t_{i2}b_{2} + \cdots + t_{in}b_{n}
$$

## Linear transformations in other bases continued

If we make a matrix $M$ whose *columns*
are the vectors $[T(b_i)]_{B}$, then

$$
[T(x)]_{B} = [ T(\sum _{i=1}^{n} r_i b_i)]_{B} = \sum r_{i}[T(b_{i})]_{B}=M[x]_{B}
$$

The matrix $M$ is called *the matrix of the linear transformation $T$ in the basis $B$* and is written

$$
M=[T]_{B}
$$

## Linear transformations and change of basis

If we write $S$ for the standard basis, the "change of basis matrix" $P_{S\leftarrow B}$ (which the book calls just $P_{B}$ has the property that
$$
P_{S\leftarrow B}[x]_{B} = [x]_{S}
$$

If $T(x) = Ax$, then in our notation above $A=[T]_{S}$ and
$x=[x]_{S}$.  We can write this equation as 
$$
[T(x)]_{S}=[T]_{S}[x]_{S}
$$

## Linear transformations and change of basis cont'd

So 
$$
[T(x)]_{S} = A[x]_{S} = AP_{S\leftarrow B}[x]_{B}
$$
But if we want the output of $T$ to *also* be in the $B$-basis, we need one more step:

$$
[T(x)]_{B} = P_{B\leftarrow S}[T(x)]_{S}=
P_{B\leftarrow S}AP_{S\leftarrow B}[x]_{B}
$$

## Linear transformations and change of basis continued

If we simplify the notation and write $P=P_{S\leftarrow B}$
then we see that
$$
[T(x)]_{B}=[T]_{B}[x]_{B}=P^{-1}AP[x]_{B}
$$
where $A=[T]_{S}$

In other words, the matrix of $T$ in the $B$-basis
is *similar* to the matrix in the standard basis.

More generally, the collection of matrices that are similar to $A=[T]_{S}$ are the collection of matrix representations of $T$ in the possible bases of $\mathbf{R}^{n}$. 

## Diagonal transformations

If the matrix $A$ is diagonalizable, then one can find a basis $B$
so that $[T]_{B}$ is a diagonal matrix. 


## Example

Suppose that $B=\{b_1, b_2\}$ is a basis for a vector space $V$ and that
$T:V\to V$ is the linear transformation defined by
$$
T(b_1) = 7b_1+4b_2, T(b_2) = 6b_1-5b_2.
$$

The matrix 
$$
[T]_{B} = \left[\begin{matrix} 7 & 6 \\ 4 & -5\end{matrix}\right]
$$

## Example continued

Is there a basis in which $T$ is given by a diagonal matrix?

The characteristic polynomial of $[T]_{B}$ is
$$
\det\left[\begin{matrix} 7-\lambda & 6 \\ 4 & -5-\lambda\end{matrix}\right]=\lambda^2-2\lambda-59
$$

The roots are $1\pm 2\sqrt{15}$.  Since these are distinct, the matrix is diagonalizable. 

## Example continued

The eigenvectors are
$$
v_{\pm} = \left[\begin{matrix} \frac{3\pm\sqrt{15}}{2} \\ 1\end{matrix}\right]
$$

and in the basis $E$ given by these eigenvectors the matrix of $T$
is diagonal.


